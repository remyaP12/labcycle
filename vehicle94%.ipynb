{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvcM8P3eH7dIalfKfRHGWH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/remyaP12/labcycle/blob/main/vehicle94%25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "F0r74gdF8srO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import (\n",
        "    silhouette_score, calinski_harabasz_score, davies_bouldin_score,\n",
        "    mean_absolute_error, mean_squared_error, r2_score\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, SimpleRNN, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LEN = 30          # longer sequences: 20‚Äì40\n",
        "TRAIN_RATIO = 0.8     # 80/20 split\n",
        "MAX_EPOCHS = 5000\n",
        "PATIENCE = 100\n",
        "USE_SMOOTH_LOAD = True        # True = rolling mean target\n",
        "USE_CLUSTER_AS_FEATURE = True # True = 1 global LSTM; False = per-cluster LSTMs"
      ],
      "metadata": {
        "id": "ppHMFSNM80Ac"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/OBD (1).csv')\n",
        "features = {\n",
        "    'rpm': 'Engine RPM(rpm)',\n",
        "    'load': 'Engine Load(%)',\n",
        "    'maf': 'Mass Air Flow Rate(g/s)',\n",
        "    'throttle': 'Throttle Position(Manifold)(%)'\n",
        "}\n",
        "df_features = df[list(features.values())].copy()\n",
        "print(f\"Dataset: {df_features.shape} | Features: {list(features.values())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_B818wu86A9",
        "outputId": "c5cae917-65c6-4630-c3cc-66c30331e7a6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: (1356, 4) | Features: ['Engine RPM(rpm)', 'Engine Load(%)', 'Mass Air Flow Rate(g/s)', 'Throttle Position(Manifold)(%)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: smooth Engine Load to reduce noise\n",
        "if USE_SMOOTH_LOAD:\n",
        "    df['Engine Load Smoothed'] = (\n",
        "        df[features['load']].rolling(5, center=True).mean().bfill().ffill()\n",
        "    )\n",
        "    load_source_col = 'Engine Load Smoothed'\n",
        "    print(\"‚úÖ Using smoothed Engine Load as target.\")\n",
        "else:\n",
        "    load_source_col = features['load']\n",
        "    print(\"‚úÖ Using raw Engine Load as target.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9Qqe02Y_6Jy",
        "outputId": "cb8a36c6-c404-4a64-a732-1830efc6eb53"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Using smoothed Engine Load as target.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_minmax = MinMaxScaler()\n",
        "scaler_robust = RobustScaler()\n",
        "\n",
        "df_features[[features['rpm'], features['maf']]] = scaler_minmax.fit_transform(\n",
        "    df_features[[features['rpm'], features['maf']]]\n",
        ")\n",
        "\n",
        "# load from chosen column, then scaled\n",
        "df_features[features['load']] = scaler_minmax.fit_transform(\n",
        "    df[[load_source_col]]\n",
        ")\n",
        "\n",
        "df_features[features['throttle']] = scaler_robust.fit_transform(\n",
        "    df_features[[features['throttle']]]\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Scaling complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqVVEeAk_6GP",
        "outputId": "fb8ebfbd-1f3a-4762-ce87-c18720e256e0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Scaling complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_cluster = df_features[list(features.values())].values\n",
        "kmeans_final = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
        "clusters = kmeans_final.fit_predict(X_cluster)\n",
        "df_features['cluster'] = clusters\n",
        "\n",
        "# cluster sizes for diagnostics\n",
        "unique, counts = np.unique(clusters, return_counts=True)\n",
        "print(\"Cluster sizes:\", dict(zip(unique, counts)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW3bf8fNAECc",
        "outputId": "86c6c382-aeef-4acb-8584-0780ad6d71fc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster sizes: {np.int32(0): np.int64(471), np.int32(1): np.int64(885)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences(data, seq_length=30, target_idx=1):\n",
        "    xs, ys = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        xs.append(data[i:i+seq_length])\n",
        "        ys.append(data[i+seq_length, target_idx])\n",
        "    return np.array(xs), np.array(ys)\n",
        "\n",
        "# base feature matrix (rpm, load, maf, throttle)\n",
        "base_seq_data = df_features[list(features.values())].values\n",
        "\n",
        "# option: add cluster id as extra feature\n",
        "if USE_CLUSTER_AS_FEATURE:\n",
        "    seq_data_full = np.concatenate([base_seq_data, clusters.reshape(-1, 1)], axis=1)\n",
        "    target_idx = list(features.values()).index(features['load'])  # still column 1\n",
        "    print(\"‚úÖ Using cluster id as additional feature (single global LSTM).\")\n",
        "else:\n",
        "    seq_data_full = base_seq_data\n",
        "    target_idx = 1  # load column in the 4-feature matrix\n",
        "    print(\"‚úÖ Will train separate LSTMs per cluster.\")\n",
        "\n",
        "X_all, y_all = create_sequences(seq_data_full, seq_length=SEQ_LEN, target_idx=target_idx)\n",
        "sequence_clusters = clusters[SEQ_LEN:]\n",
        "\n",
        "print(f\"‚úÖ Sequences: X_all={X_all.shape}, y_all={y_all.shape}\")\n",
        "\n",
        "# global train/test split (80/20, time-ordered)\n",
        "split_global = int(TRAIN_RATIO * len(X_all))\n",
        "X_train_global, X_test_global = X_all[:split_global], X_all[split_global:]\n",
        "y_train_global, y_test_global = y_all[:split_global], y_all[split_global:]\n",
        "clusters_train_global = sequence_clusters[:split_global]\n",
        "clusters_test_global = sequence_clusters[split_global:]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRT1byV8AD-6",
        "outputId": "2059ec8f-420f-4342-f232-18ee773e7cfc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Using cluster id as additional feature (single global LSTM).\n",
            "‚úÖ Sequences: X_all=(1326, 30, 5), y_all=(1326,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_lstm(input_shape):\n",
        "    model = Sequential([\n",
        "        LSTM(76, return_sequences=True, input_shape=input_shape),\n",
        "        Dropout(0.2),\n",
        "        LSTM(76),\n",
        "        Dropout(0.5),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0002), loss='mse')\n",
        "    return model\n",
        "\n",
        "def build_gru(input_shape):\n",
        "    model = Sequential([\n",
        "        GRU(76, return_sequences=True, input_shape=input_shape),\n",
        "        Dropout(0.2),\n",
        "        GRU(76),\n",
        "        Dropout(0.5),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0002), loss='mse')\n",
        "    return model\n",
        "\n",
        "def build_rnn(input_shape):\n",
        "    model = Sequential([\n",
        "        SimpleRNN(76, return_sequences=True, input_shape=input_shape),\n",
        "        Dropout(0.2),\n",
        "        SimpleRNN(76),\n",
        "        Dropout(0.5),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0002), loss='mse')\n",
        "    return model\n",
        "\n",
        "def train_and_predict(build_fn, X_train, y_train, X_test):\n",
        "    model = build_fn((X_train.shape[1], X_train.shape[2]))\n",
        "    es = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=PATIENCE,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=MAX_EPOCHS,\n",
        "        batch_size=32,\n",
        "        validation_split=0.1,\n",
        "        callbacks=[es],\n",
        "        verbose=0\n",
        "    )\n",
        "    y_pred = model.predict(X_test, verbose=0).ravel()\n",
        "    return model, y_pred"
      ],
      "metadata": {
        "id": "klvzf7_YAD8b"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n‚è≥ Training LSTM-only...\")\n",
        "lstm_model, y_pred_lstm = train_and_predict(\n",
        "    build_lstm, X_train_global, y_train_global, X_test_global\n",
        ")\n",
        "\n",
        "print(\"‚è≥ Training GRU...\")\n",
        "gru_model, y_pred_gru = train_and_predict(\n",
        "    build_gru, X_train_global, y_train_global, X_test_global\n",
        ")\n",
        "\n",
        "print(\"‚è≥ Training RNN...\")\n",
        "rnn_model, y_pred_rnn = train_and_predict(\n",
        "    build_rnn, X_train_global, y_train_global, X_test_global\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsDO9RPoAD6e",
        "outputId": "dbde66f6-65ee-45a4-da2e-d39b0a7cb8e3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚è≥ Training LSTM-only...\n",
            "‚è≥ Training GRU...\n",
            "‚è≥ Training RNN...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if USE_CLUSTER_AS_FEATURE:\n",
        "    # hybrid = single global LSTM, already trained above\n",
        "    # use y_pred_lstm as \"Proposed\" predictions\n",
        "    y_pred_hybrid = y_pred_lstm.copy()\n",
        "    print(\"‚úÖ Hybrid = global LSTM with cluster feature.\")\n",
        "else:\n",
        "    # true per-cluster hybrid\n",
        "    cluster_models = {}\n",
        "    for c in np.unique(sequence_clusters):\n",
        "        idx_c = np.where(sequence_clusters == c)[0]\n",
        "        X_c, y_c = X_all[idx_c], y_all[idx_c]\n",
        "        if len(X_c) < 100:\n",
        "            print(f\"‚ö†Ô∏è Cluster {c} has only {len(X_c)} sequences; model may be weak.\")\n",
        "        split_c = int(TRAIN_RATIO * len(X_c))\n",
        "        X_train_c, X_test_c = X_c[:split_c], X_c[split_c:]\n",
        "        y_train_c, y_test_c = y_c[:split_c], y_c[split_c:]\n",
        "\n",
        "        print(f\"\\n‚è≥ Training LSTM for cluster {c} (samples: {len(X_c)})...\")\n",
        "        model_c, _ = train_and_predict(\n",
        "            build_lstm, X_train_c, y_train_c, X_test_c\n",
        "        )\n",
        "        cluster_models[c] = model_c\n",
        "\n",
        "    y_pred_hybrid = []\n",
        "    for seq, c in zip(X_test_global, clusters_test_global):\n",
        "        model_c = cluster_models[c]\n",
        "        y_hat = model_c.predict(seq[np.newaxis, ...], verbose=0)[0, 0]\n",
        "        y_pred_hybrid.append(y_hat)\n",
        "    y_pred_hybrid = np.array(y_pred_hybrid)\n",
        "    print(\"‚úÖ Hybrid = per-cluster LSTMs.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0McGA3TbAD3r",
        "outputId": "f7d6edce-7615-442d-fef3-c476f07637bc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Hybrid = global LSTM with cluster feature.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def metrics(y_true, y_pred):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return mae, mse, rmse, r2\n",
        "\n",
        "mae_l, mse_l, rmse_l, r2_l = metrics(y_test_global, y_pred_lstm)\n",
        "mae_g, mse_g, rmse_g, r2_g = metrics(y_test_global, y_pred_gru)\n",
        "mae_r, mse_r, rmse_r, r2_r = metrics(y_test_global, y_pred_rnn)\n",
        "mae_h, mse_h, rmse_h, r2_h = metrics(y_test_global, y_pred_hybrid)\n",
        "\n",
        "comparison = pd.DataFrame({\n",
        "    'Model': ['LSTM only', 'GRU', 'RNN', 'Proposed (Hybrid)'],\n",
        "    'MAE': [mae_l, mae_g, mae_r, mae_h],\n",
        "    'MSE': [mse_l, mse_g, mse_r, mse_h],\n",
        "    'RMSE (%)': [rmse_l * 100, rmse_g * 100, rmse_r * 100, rmse_h * 100],\n",
        "    'R2 (%)': [r2_l * 100, r2_g * 100, r2_r * 100, r2_h * 100]\n",
        "}).round(4)\n",
        "\n",
        "print(\"\\nüìä Model performance comparison (Engine Load target):\")\n",
        "print(comparison)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVb8ruSG_6Dm",
        "outputId": "32473fe0-4fc6-47ac-9d91-c5ba21b9d02f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Model performance comparison (Engine Load target):\n",
            "               Model     MAE     MSE  RMSE (%)   R2 (%)\n",
            "0          LSTM only  0.0442  0.0030    5.5107  94.1532\n",
            "1                GRU  0.0402  0.0025    5.0288  95.1311\n",
            "2                RNN  0.0404  0.0027    5.2207  94.7523\n",
            "3  Proposed (Hybrid)  0.0442  0.0030    5.5107  94.1532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TCUJkO5h_6Bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1EXtramL_5-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_minmax = MinMaxScaler()\n",
        "scaler_robust = RobustScaler()\n",
        "\n",
        "df_features[[features['rpm'], features['maf']]] = scaler_minmax.fit_transform(\n",
        "    df_features[[features['rpm'], features['maf']]]\n",
        ")"
      ],
      "metadata": {
        "id": "8MiwTz9h9JbD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load from chosen column, then scaled\n",
        "df_features[features['load']] = scaler_minmax.fit_transform(\n",
        "    df[[load_source_col]]\n",
        ")\n",
        "\n",
        "df_features[features['throttle']] = scaler_robust.fit_transform(\n",
        "    df_features[[features['throttle']]]\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Scaling complete.\")\n",
        "\n",
        "# ============================================================\n",
        "# 3. K-MEANS CLUSTERING (K=2)\n",
        "# ============================================================\n",
        "X_cluster = df_features[list(features.values())].values\n",
        "kmeans_final = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
        "clusters = kmeans_final.fit_predict(X_cluster)\n",
        "df_features['cluster'] = clusters\n",
        "\n",
        "# cluster sizes for diagnostics\n",
        "unique, counts = np.unique(clusters, return_counts=True)\n",
        "print(\"Cluster sizes:\", dict(zip(unique, counts)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "j4FE90ow9JYp",
        "outputId": "913bd2a9-ed36-4ca0-dcfc-c1fbf808a742"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'load_source_col' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-646378385.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load from chosen column, then scaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m df_features[features['load']] = scaler_minmax.fit_transform(\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mload_source_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'load_source_col' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uM3zPyEZ9JWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8ptoHNkg9JUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mQL2OrVF9JRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HF7iEccV9JPI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}